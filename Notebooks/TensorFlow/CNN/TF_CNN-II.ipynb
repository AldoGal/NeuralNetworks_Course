{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "The goal in this task is to take an image of a handwritten single digit, and determine what that digit is.  \n",
    "\n",
    "The data for this competition were taken from the MNIST dataset. The MNIST (\"Modified National Institute of Standards and Technology\") dataset is a classic within the Machine Learning community that has been extensively studied.  More detail about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pylab\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../../../data/\"\n",
    "outputs = \"../../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data from CSV file \n",
    "\n",
    "with ZipFile(os.path.join(datapath, 'kaggle_digits_train.zip'), 'r') as myzip:\n",
    "    with myzip.open('kaggle_digits_train.csv') as myfile:\n",
    "        train_data = pd.read_csv(myfile)\n",
    "        \n",
    "with ZipFile(os.path.join(datapath, 'kaggle_digits_test.zip'), 'r') as myzip:\n",
    "    with myzip.open('kaggle_digits_test.csv') as myfile:\n",
    "        test_data = pd.read_csv(myfile)\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(train_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image is a \"stretched\" array of pixel values.  \n",
    "In this case it's 784 pixels => 28 * 28 px  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images numpy array have shape: (42000,784)\n"
     ]
    }
   ],
   "source": [
    "images = train_data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "print('images numpy array have shape: ({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f29d916a88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_TO_DISPLAY = 10\n",
    "\n",
    "# (784) => (28,28)\n",
    "plt.imshow(images[IMAGE_TO_DISPLAY].reshape((28, 28)), cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(42000)\n",
      "labels_flat[10] => 8\n"
     ]
    }
   ],
   "source": [
    "labels_flat = train_data.iloc[:,0].values\n",
    "\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for i in range(0,9):\n",
    "    plt.subplot(250 + (i+1))\n",
    "    img = images[i,:].reshape(28, 28)\n",
    "    plt.imshow(img, cmap='Greys')\n",
    "    plt.title(labels_flat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_count => 10\n"
     ]
    }
   ],
   "source": [
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "print('labels_count => {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = test_data.values.astype(np.float)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images(25200,784)\n",
      "validation images(16800,784)\n",
      "train labels((25200,))\n",
      "validation labels((16800,))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(images, \n",
    "                                                                    labels_flat, \n",
    "                                                                    test_size=0.4, \n",
    "                                                                    random_state=0)\n",
    "print('train images({0[0]},{0[1]})'.format(X_train.shape))\n",
    "print('validation images({0[0]},{0[1]})'.format(X_test.shape))\n",
    "print('train labels({})'.format(y_train.shape))\n",
    "print('validation labels({})'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create and train the random forest\n",
    "# multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "clf_rf = RandomForestClassifier(n_estimators=300, \n",
    "                                criterion='gini', \n",
    "                                max_depth=None, \n",
    "                                min_samples_split=3, \n",
    "                                min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features='auto', \n",
    "                                max_leaf_nodes=None, \n",
    "                                bootstrap=True, \n",
    "                                oob_score=False, \n",
    "                                n_jobs=-1, \n",
    "                                random_state=0, \n",
    "                                verbose=0, \n",
    "                                warm_start=False, \n",
    "                                class_weight=None).fit(X_train, y_train)\n",
    "\n",
    "eval_rf = clf_rf.score(X_test, y_test)\n",
    "print(eval_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9720833333333333\n"
     ]
    }
   ],
   "source": [
    "# Train SVM...\n",
    "from sklearn import svm\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "clf_svm = svm.SVC(kernel='poly',\n",
    "                  C=1.57,\n",
    "                  degree=2, \n",
    "                  gamma=0.278,\n",
    "                  coef0=0.0, \n",
    "                  shrinking=True, \n",
    "                  probability=False, \n",
    "                  tol=0.001, \n",
    "                  cache_size=200, \n",
    "                  class_weight=None, \n",
    "                  verbose=False, \n",
    "                  max_iter=-1, \n",
    "                  random_state=0).fit(X_train, y_train)\n",
    "\n",
    "eval_svm = clf_svm.score(X_test, y_test)\n",
    "print(eval_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 9, 3, 7, 0, 3, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = clf_rf.predict(test_images)\n",
    "predict_rf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_svm = clf_svm.predict(test_images)\n",
    "predict_svm[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensor Flow (with a fully connected ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "model.evaluate(x_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensor Flow (with a CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "# baseline cnn model for mnist\n",
    "\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# one hot encode target values\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)\n",
    "# scale pixels\n",
    "trainX, testX = prep_pixels(trainX, testX)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),\n",
    "                                    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam', #SGD(lr=0.01, momentum=0.9)\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(trainX, trainY, epochs=10)\n",
    "model.evaluate(testX, testY, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.keras.datasets import mnist\n",
    "from tf.keras.utils import to_categorical\n",
    "from tf.keras.models import Sequential\n",
    "from tf.keras.layers import Conv2D\n",
    "from tf.keras.layers import MaxPooling2D\n",
    "from tf.keras.layers import Dense\n",
    "from tf.keras.layers import Flatten\n",
    "from tf.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
    "              optimizer=tf.keras.optimizers.Adadelta(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.acc, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_acc, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing a more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://sihamtabik.github.io/LeNet-like-CNN.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters_1 = 32 # 64\n",
    "nb_filters_2 = 64 # 128\n",
    "nb_filters_3 = 128 # 256\n",
    "nb_conv = 3\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1,1), input_shape=input_shape,))\n",
    "model.add(Conv2D(nb_filters_1, (nb_conv, nb_conv),  activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_1, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_2, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_2, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adadelta\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.acc, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_acc, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Using the LENET architecture](https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/  )\n",
    "\n",
    "The LeNet architecture was first introduced by LeCun et al. in their 1998 paper, Gradient-Based Learning Applied to Document Recognition. As the name of the paper suggests, the authors’ implementation of LeNet was used primarily for OCR and character recognition in documents.  \n",
    "\n",
    "The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs — it can even run on the CPU (if your system does not have a suitable GPU), making it a great “first CNN”.  \n",
    "\n",
    "However, if you do have GPU support and can access your GPU via Keras, you will enjoy extremely fast training times (in the order of 3-10 seconds per epoch, depending on your GPU).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(os.path.join('../datasets/','Figs', 'lenet_architecture-768x226.png'), width=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, weightsPath=None):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        # first set of CONV => RELU => POOL\n",
    "        model.add(ZeroPadding2D((1,1), input_shape=input_shape,))\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(depth, height, width)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # second set of CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        # if a weights path is supplied (inicating that the model was\n",
    "        # pre-trained), then load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=img_rows, \n",
    "                    height=img_cols, \n",
    "                    depth=1, \n",
    "                    classes=10,\n",
    "                    #weightsPath=args[\"weights\"] if args[\"load_model\"] > 0 else None\n",
    "                   )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adadelta\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.acc, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_acc, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-trained models  \n",
    "\n",
    "How can I use pre-trained models in Keras?  \n",
    "Code and pre-trained weights are available for the following image classification models:  \n",
    "+ Xception  \n",
    "+ VGG16  \n",
    "+ VGG19  \n",
    "+ ResNet50  \n",
    "+ Inception v3  \n",
    "\n",
    "They can be imported from the module [keras.applications](https://keras.io/applications/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.xception import Xception\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building powerful image classification models using very little data:  \n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Neural Net Frameworks:  \n",
    "https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Visualizing the classification task:](http://scs.ryerson.ca/~aharley/vis/fc/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
