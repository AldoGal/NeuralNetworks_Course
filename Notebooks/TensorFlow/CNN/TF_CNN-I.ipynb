{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>\n",
    "\n",
    "[source](https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/mnist.png)\n",
    "\n",
    "The goal in this task is to take an image of a handwritten single digit, and determine what that digit is.  \n",
    "\n",
    "The data for this competition were taken from the MNIST dataset. The MNIST (\"Modified National Institute of Standards and Technology\") dataset is a classic within the Machine Learning community that has been extensively studied.  More detail about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pylab\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# let's print the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3802 - accuracy: 0.8952 - val_loss: 0.2084 - val_accuracy: 0.9409\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9483 - val_loss: 0.1542 - val_accuracy: 0.9544\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1312 - accuracy: 0.9629 - val_loss: 0.1214 - val_accuracy: 0.9648\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9708 - val_loss: 0.1046 - val_accuracy: 0.9691\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9754 - val_loss: 0.0918 - val_accuracy: 0.9718\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0702 - accuracy: 0.9798 - val_loss: 0.0881 - val_accuracy: 0.9721\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0602 - accuracy: 0.9824 - val_loss: 0.0812 - val_accuracy: 0.9748\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0510 - accuracy: 0.9855 - val_loss: 0.0764 - val_accuracy: 0.9762\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0433 - accuracy: 0.9883 - val_loss: 0.0722 - val_accuracy: 0.9767\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0377 - accuracy: 0.9894 - val_loss: 0.0746 - val_accuracy: 0.9772\n",
      "Wall time: 7.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f306b717c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "%time model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 538us/step - loss: 0.0746 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07460634410381317, 0.9771999716758728]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 25)        250       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 25)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16900)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               1690100   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 1,691,360\n",
      "Trainable params: 1,691,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.2074 - accuracy: 0.9414 - val_loss: 0.0884 - val_accuracy: 0.9719\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0617 - accuracy: 0.9818 - val_loss: 0.0593 - val_accuracy: 0.9813\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0611 - val_accuracy: 0.9805\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0537 - val_accuracy: 0.9845\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0533 - val_accuracy: 0.9848\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0573 - val_accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 25s 52ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0562 - val_accuracy: 0.9853\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0593 - val_accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0623 - val_accuracy: 0.9845\n",
      "Wall time: 4min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f3152d21c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "\n",
    "# training the model for 10 epochs\n",
    "%time model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0623 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06232215091586113, 0.984499990940094]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
