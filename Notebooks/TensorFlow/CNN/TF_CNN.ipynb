{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "The goal in this competition is to take an image of a handwritten single digit, and determine what that digit is.  \n",
    "\n",
    "The data for this competition were taken from the MNIST dataset. The MNIST (\"Modified National Institute of Standards and Technology\") dataset is a classic within the Machine Learning community that has been extensively studied.  More detail about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.altoros.com/blog/wp-content/uploads/2017/01/mnist.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://www.altoros.com/blog/wp-content/uploads/2017/01/mnist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.  \n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.  \n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.  \n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).  \n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.  \n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:  \n",
    "\n",
    "000 001 002 003 ... 026 027  \n",
    "028 029 030 031 ... 054 055  \n",
    "056 057 058 059 ... 082 083  \n",
    "                ...  \n",
    "728 729 730 731 ... 754 755  \n",
    "756 757 758 759 ... 782 783  \n",
    "\n",
    "\n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "Your submission file should be in the following format: For each of the 28000 images in the test set, output a single line containing the ImageId and the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:  \n",
    "\n",
    "ImageId,Label  \n",
    "1,3  \n",
    "2,7  \n",
    "3,8  \n",
    "(27997 more lines)\n",
    "\n",
    "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images.  \n",
    "\n",
    "Additional Material: https://hackernoon.com/what-is-a-capsnet-or-capsule-network-2bfbe48769cc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading packages...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pylab\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../../../data/\"\n",
    "outputs = \"../../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data from CSV file \n",
    "\n",
    "with ZipFile(os.path.join(datapath, 'kaggle_digits_train.zip'), 'r') as myzip:\n",
    "    with myzip.open('kaggle_digits_train.csv') as myfile:\n",
    "        train_data = pd.read_csv(myfile)\n",
    "        \n",
    "with ZipFile(os.path.join(datapath, 'kaggle_digits_test.zip'), 'r') as myzip:\n",
    "    with myzip.open('kaggle_digits_test.csv') as myfile:\n",
    "        test_data = pd.read_csv(myfile)\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(train_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image is a \"stretched\" array of pixel values.  \n",
    "In this case it's 784 pixels => 28 * 28 px  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images numpy array have shape: (42000,784)\n"
     ]
    }
   ],
   "source": [
    "images = train_data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "print('images numpy array have shape: ({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f786ab860a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_TO_DISPLAY = 10\n",
    "\n",
    "# (784) => (28,28)\n",
    "plt.imshow(images[IMAGE_TO_DISPLAY].reshape((28, 28)), cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(42000)\n",
      "labels_flat[10] => 8\n"
     ]
    }
   ],
   "source": [
    "labels_flat = train_data.iloc[:,0].values\n",
    "\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for i in range(0,9):\n",
    "    plt.subplot(250 + (i+1))\n",
    "    img = images[i,:].reshape(28, 28)\n",
    "    plt.imshow(img, cmap='Greys')\n",
    "    plt.title(labels_flat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_count => 10\n"
     ]
    }
   ],
   "source": [
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "print('labels_count => {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = test_data.values.astype(np.float)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images(25200,784)\n",
      "validation images(16800,784)\n",
      "train labels((25200,))\n",
      "validation labels((16800,))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(images, \n",
    "                                                                    labels_flat, \n",
    "                                                                    test_size=0.4, \n",
    "                                                                    random_state=0)\n",
    "print('train images({0[0]},{0[1]})'.format(X_train.shape))\n",
    "print('validation images({0[0]},{0[1]})'.format(X_test.shape))\n",
    "print('train labels({})'.format(y_train.shape))\n",
    "print('validation labels({})'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create and train the random forest\n",
    "# multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "clf_rf = RandomForestClassifier(n_estimators=300, \n",
    "                                criterion='gini', \n",
    "                                max_depth=None, \n",
    "                                min_samples_split=3, \n",
    "                                min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features='auto', \n",
    "                                max_leaf_nodes=None, \n",
    "                                bootstrap=True, \n",
    "                                oob_score=False, \n",
    "                                n_jobs=-1, \n",
    "                                random_state=0, \n",
    "                                verbose=0, \n",
    "                                warm_start=False, \n",
    "                                class_weight=None).fit(X_train, y_train)\n",
    "\n",
    "eval_rf = clf_rf.score(X_test, y_test)\n",
    "print(eval_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9720833333333333\n"
     ]
    }
   ],
   "source": [
    "# Train SVM...\n",
    "from sklearn import svm\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "clf_svm = svm.SVC(kernel='poly',\n",
    "                  C=1.57,\n",
    "                  degree=2, \n",
    "                  gamma=0.278,\n",
    "                  coef0=0.0, \n",
    "                  shrinking=True, \n",
    "                  probability=False, \n",
    "                  tol=0.001, \n",
    "                  cache_size=200, \n",
    "                  class_weight=None, \n",
    "                  verbose=False, \n",
    "                  max_iter=-1, \n",
    "                  random_state=0).fit(X_train, y_train)\n",
    "\n",
    "eval_svm = clf_svm.score(X_test, y_test)\n",
    "print(eval_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 9, 3, 7, 0, 3, 0, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf = clf_rf.predict(test_images)\n",
    "predict_rf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 0, 3, 7, 0, 3, 0, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_svm = clf_svm.predict(test_images)\n",
    "predict_svm[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensor Flow (fully connected ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2977 - accuracy: 0.9144\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1416 - accuracy: 0.9578\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1065 - accuracy: 0.9679\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0881 - accuracy: 0.9726\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0743 - accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0657 - accuracy: 0.9796\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0576 - accuracy: 0.9815\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0526 - accuracy: 0.9829\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0488 - accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0446 - accuracy: 0.9852\n",
      "313/313 [==============================] - 0s 785us/step - loss: 0.0731 - accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07314179092645645, 0.9797000288963318]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "model.evaluate(x_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a CNN Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    " \n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    " \n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    " \n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# stores scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(2, 1, 1)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(2, 1, 2)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    " \n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_1 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [None, 28, 28]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c4bd11618783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    204\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    926\u001b[0m                                                 input_list)\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    192\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                          \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_1 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [None, 28, 28]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "model.evaluate(x_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
    "              optimizer=tf.keras.optimizers.Adadelta(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.acc, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_acc, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing a more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://sihamtabik.github.io/LeNet-like-CNN.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters_1 = 32 # 64\n",
    "nb_filters_2 = 64 # 128\n",
    "nb_filters_3 = 128 # 256\n",
    "nb_conv = 3\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1,1), input_shape=input_shape,))\n",
    "model.add(Conv2D(nb_filters_1, (nb_conv, nb_conv),  activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_1, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_2, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_2, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adadelta\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.acc, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_acc, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Using the LENET architecture](https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/  )\n",
    "\n",
    "The LeNet architecture was first introduced by LeCun et al. in their 1998 paper, Gradient-Based Learning Applied to Document Recognition. As the name of the paper suggests, the authors’ implementation of LeNet was used primarily for OCR and character recognition in documents.  \n",
    "\n",
    "The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs — it can even run on the CPU (if your system does not have a suitable GPU), making it a great “first CNN”.  \n",
    "\n",
    "However, if you do have GPU support and can access your GPU via Keras, you will enjoy extremely fast training times (in the order of 3-10 seconds per epoch, depending on your GPU).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(os.path.join('../datasets/','Figs', 'lenet_architecture-768x226.png'), width=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, weightsPath=None):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        # first set of CONV => RELU => POOL\n",
    "        model.add(ZeroPadding2D((1,1), input_shape=input_shape,))\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(depth, height, width)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # second set of CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        # if a weights path is supplied (inicating that the model was\n",
    "        # pre-trained), then load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=img_rows, \n",
    "                    height=img_cols, \n",
    "                    depth=1, \n",
    "                    classes=10,\n",
    "                    #weightsPath=args[\"weights\"] if args[\"load_model\"] > 0 else None\n",
    "                   )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adadelta\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.acc, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_acc, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-trained models  \n",
    "\n",
    "How can I use pre-trained models in Keras?  \n",
    "Code and pre-trained weights are available for the following image classification models:  \n",
    "+ Xception  \n",
    "+ VGG16  \n",
    "+ VGG19  \n",
    "+ ResNet50  \n",
    "+ Inception v3  \n",
    "\n",
    "They can be imported from the module [keras.applications](https://keras.io/applications/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.xception import Xception\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building powerful image classification models using very little data:  \n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Neural Net Frameworks:  \n",
    "https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Visualizing the classification task:](http://scs.ryerson.ca/~aharley/vis/fc/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
