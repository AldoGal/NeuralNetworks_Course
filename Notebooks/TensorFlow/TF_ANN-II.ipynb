{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed4cd7c86887522b8c8d4b8c3c53ba1027949f9b"
   },
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Intro to Tensor Flow and Keras - preprocessing</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install -U tensorflow tensorboard  \n",
    "#!pip install -q tensorflow==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "#import re\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api_pb2\n",
    "from tensorboard.plugins.hparams import summary as hparams_summary\n",
    "%load_ext tensorboard\n",
    "\n",
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-35f177b16f3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Clear any logs from previous runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rm -rf ./logs/ '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input'"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/train.csv\")\n",
    "test_data = pd.read_csv(\"../input/test.csv\")\n",
    "train_data.info()\n",
    "print('_'*50)\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23de2def20bde7868eb192a2c5edb9769bed11d9"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6aa1d7bbd96a25ce685a1d8fe7fa9451e7b069d4"
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93aa50436d06d1fdece8970d469b0b329ef45d8c"
   },
   "source": [
    "#### Drop the columns if the missing values are more than 20% of the data. Drop missing rows otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b18e532419264e9ca433a984e3974a0065ba3a5"
   },
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    if len(train_data[col].dropna()) <= (0.7 * len(train_data)):\n",
    "        train_data.drop(columns=[col], inplace=True)\n",
    "    else:\n",
    "        train_data.dropna(axis=0, subset=[col],inplace=True)\n",
    "\n",
    "for col in test_data.columns:\n",
    "    if len(test_data[col].dropna()) <= (0.7 * len(test_data)):\n",
    "        test_data.drop(columns=[col], inplace=True)\n",
    "    else:\n",
    "        test_data[col].fillna(value=test_data[col].mode()[0] ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c09d970d277431fa78e24ec009ea51bdc64fa41"
   },
   "outputs": [],
   "source": [
    "train_data.info()\n",
    "print('_'*50)\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6786728f751be8769471c80f5daadd20839ed7ff"
   },
   "source": [
    "No need to convert the data types from categorical to numerical because we want tensorflow to handle this kind of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af22d7039852eebe20955e0de24bc949093dbcfb"
   },
   "source": [
    "#### Define Feature columns for tensorflow  \n",
    "Examples of each column type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4994ae2c85b8c73ec22b312a12e15e369572280"
   },
   "outputs": [],
   "source": [
    "# Just to see the correlation\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(train_data.corr(method='pearson'),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "652d3d496e465bf60d5aef33f79e6f180c082dc7"
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['Age', 'Fare']:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(header))\n",
    "\n",
    "# bucketized cols\n",
    "age = tf.feature_column.numeric_column(\"Age\")\n",
    "age_buckets = tf.feature_column.bucketized_column(age, boundaries=[5, 10, 20, 30, 40, 50, 60, 70, 80])\n",
    "feature_columns.append(age_buckets)\n",
    "\n",
    "# indicator cols\n",
    "categorical_cols = [\"Sex\", \"Embarked\", \"Pclass\", \"SibSp\", \"Parch\"]\n",
    "for col in categorical_cols:\n",
    "    train_data[col] = train_data[col].apply(str)\n",
    "    test_data[col] = test_data[col].apply(str)\n",
    "    cat_column_with_vocab = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "          col, list(train_data[col].value_counts().index.values))\n",
    "    one_hot = tf.feature_column.indicator_column(cat_column_with_vocab)\n",
    "    feature_columns.append(one_hot)\n",
    "\n",
    "\n",
    "# embedding cols\n",
    "ticket = tf.feature_column.categorical_column_with_hash_bucket(\"Ticket\", hash_bucket_size=1000)\n",
    "ticket_embedding = tf.feature_column.embedding_column(ticket, dimension=8)\n",
    "feature_columns.append(ticket_embedding)\n",
    "\n",
    "# crossed cols\n",
    "p_class = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "          \"Pclass\", list(train_data[\"Pclass\"].value_counts().index.values))\n",
    "parch = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "          \"Parch\", list(train_data[\"Parch\"].value_counts().index.values))\n",
    "pclass_parch_crossed = tf.feature_column.crossed_column([p_class, parch], hash_bucket_size=1000)\n",
    "pclass_parch_crossed = tf.feature_column.indicator_column(pclass_parch_crossed)\n",
    "feature_columns.append(pclass_parch_crossed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "869e25aea4077c3327535181afa45dd68e91a21e"
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, testing=False, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    if not testing:\n",
    "        labels = dataframe.pop('Survived')\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81002699b6013bc68b4ec8b6f236d2ac372df3f0"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1daff759cc6bd037835cda13c7ad1845257f77d"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train_data, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_data, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test_data, testing=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf4ed1dccc9630b9f75050016c4d5d4d450925c5"
   },
   "source": [
    "### Setup Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f72637b62bcdaaaab92fa467bbdedf3ea0f69f7c"
   },
   "outputs": [],
   "source": [
    "num_units_list = [128, 256]\n",
    "dropout_rate_list = [0.2, 0.5] \n",
    "optimizer_list = ['adam', 'sgd'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "365d776a86a163d36eba9eeedf318be60a46ad5d"
   },
   "outputs": [],
   "source": [
    "# Utility method to create summary for tensorboard\n",
    "def create_experiment_summary(num_units_list, dropout_rate_list, optimizer_list):\n",
    "  num_units_list_val = struct_pb2.ListValue()\n",
    "  num_units_list_val.extend(num_units_list)\n",
    "  dropout_rate_list_val = struct_pb2.ListValue()\n",
    "  dropout_rate_list_val.extend(dropout_rate_list)\n",
    "  optimizer_list_val = struct_pb2.ListValue()\n",
    "  optimizer_list_val.extend(optimizer_list)\n",
    "  return hparams_summary.experiment_pb(\n",
    "      # The hyperparameters being changed\n",
    "      hparam_infos=[\n",
    "          api_pb2.HParamInfo(name='num_units',\n",
    "                             display_name='Number of units',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=num_units_list_val),\n",
    "          api_pb2.HParamInfo(name='dropout_rate',\n",
    "                             display_name='Dropout rate',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=dropout_rate_list_val),\n",
    "          api_pb2.HParamInfo(name='optimizer',\n",
    "                             display_name='Optimizer',\n",
    "                             type=api_pb2.DATA_TYPE_STRING,\n",
    "                             domain_discrete=optimizer_list_val)\n",
    "      ],\n",
    "      # The metrics being tracked\n",
    "      metric_infos=[\n",
    "          api_pb2.MetricInfo(\n",
    "              name=api_pb2.MetricName(\n",
    "                  tag='accuracy'),\n",
    "              display_name='Accuracy'),\n",
    "      ]\n",
    "  )\n",
    "\n",
    "exp_summary = create_experiment_summary(num_units_list, dropout_rate_list, optimizer_list)\n",
    "root_logdir_writer = tf.summary.create_file_writer(\"logs/hparam_tuning\")\n",
    "with root_logdir_writer.as_default():\n",
    "  tf.summary.import_event(tf.compat.v1.Event(summary=exp_summary).SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00c52b5e1da3208d7a718602f9783ba045f1742b"
   },
   "outputs": [],
   "source": [
    "# Model compiler\n",
    "def train_test_model(hparams):\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(hparams['num_units'], activation='relu'),\n",
    "    tf.keras.layers.Dropout(hparams['dropout_rate']),\n",
    "      tf.keras.layers.Dense(hparams['num_units'], activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(optimizer=hparams['optimizer'],\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(train_ds, \n",
    "            validation_data=val_ds, \n",
    "            epochs=50,\n",
    "            use_multiprocessing=True,\n",
    "            verbose=0)\n",
    "  _, accuracy = model.evaluate(val_ds)\n",
    "  return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce40f4ef18a980e04f4647e25a97c39345fe3f64"
   },
   "outputs": [],
   "source": [
    "# Model runner\n",
    "def run(run_dir, hparams):\n",
    "  writer = tf.summary.create_file_writer(run_dir)\n",
    "  summary_start = hparams_summary.session_start_pb(hparams=hparams)\n",
    "\n",
    "  with writer.as_default():\n",
    "    model, accuracy = train_test_model(hparams)\n",
    "    summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\n",
    "      \n",
    "    tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\n",
    "    tf.summary.import_event(tf.compat.v1.Event(summary=summary_start).SerializeToString())\n",
    "    tf.summary.import_event(tf.compat.v1.Event(summary=summary_end).SerializeToString())\n",
    "  return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28941b640efbd4b5dd7973f072f2d4dc20ae2a8c"
   },
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "session_num = 0\n",
    "for num_units in num_units_list:\n",
    "    for dropout_rate in dropout_rate_list:\n",
    "        for optimizer in optimizer_list:\n",
    "            hparams = {'num_units': num_units, 'dropout_rate': dropout_rate, 'optimizer': optimizer}\n",
    "            print('--- Running training session %d' % (session_num + 1))\n",
    "            print(hparams)\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            model, accuracy = run(\"logs/hparam_tuning/\" + run_name, hparams)\n",
    "            print(accuracy)\n",
    "            model_dict[accuracy] = model\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91a3242fdeccecb9d49e00c2c0462bb81736165f"
   },
   "outputs": [],
   "source": [
    "best_model = model_dict[max(list(model_dict.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6bc6e36e0a4064ebd24c1565e1388e700020bfe2"
   },
   "outputs": [],
   "source": [
    "predictions = best_model.predict(test_ds)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "861ce10c0b7becb306c1227f03ce236cf10fd780"
   },
   "outputs": [],
   "source": [
    "predictions_dataframe = test_data[[\"PassengerId\"]]\n",
    "predictions_dataframe[\"Survived\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0986b2e992c217af9c3d9c45a1ced4502e963afe"
   },
   "outputs": [],
   "source": [
    "predictions_dataframe.to_csv(\"gender_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f3149b86a86d81e8c7f1b71d5963f46b2632ea2"
   },
   "outputs": [],
   "source": [
    "best_model.save('best_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
